from matplotlib import table
import yfinance as yf
import pandas as pd
import commonHelper as ch
import plotly.graph_objects as go
import plotly.io as pio
import time
import json
import random
import concurrent.futures
import sys
import math
import requests
import datetime

from db_financialStatement import DB_FinancialStatement
from db_stock import DB_Stock
from db_nyse import DB_NYSE
from tqdm import tqdm  # ì§„í–‰ë¥ 
from mysqlConnecter import MySQLConnector
from yFinanceInfo import YFinanceInfo
from selenium.common.exceptions import NoSuchElementException, TimeoutException
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup
from IPython.display import display
from selenium import webdriver
from selenium.webdriver.chrome.options import Options


class DataDownloader:
    def __new__(cls, *args, **kwargs):
        raise TypeError("ì´ í´ë˜ìŠ¤ëŠ” ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë§Œë“¤ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (Static class ë°©ì‹)")
    
      
    #--------------------
    # ì¬ë¬´ì¬í‘œ DBì €ì¥
    #--------------------
    def save_fs_to_db(stockInfo, conn, type, dateType): 
        infoName = ch.getStrFinancialStatementType(type)
        dateName = ch.getStrDateType(dateType)

        tableName = f"{infoName}_{dateName}"

        try:
            df = stockInfo.getFsData(type, dateType)
        
            if df is None:
                print(f"âŒ {tableName} {type} {dateType} ì˜ dfê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

            df = df.where(pd.notna(df), None)
            if df.empty:
                print(f"âŒ {tableName} ë°ì´í„° ì—†ìŒ")
                return


            symbol = stockInfo.stock.info.get('symbol','N/A')
            name = stockInfo.stock.info.get('shortName','N/A')

            df = df.T
            df.reset_index(inplace=True)
            df.rename(columns={"index": "Date"}, inplace=True)
            df.columns = [col.replace(' ', '').replace('-', '') for col in df.columns]
            # df.columns = [
            #     (col[0].lower() + col[1:]) if col and col[0].isupper() else col
            #     for col in df.columns
            # ]
            df['Symbol'] = symbol
            df['Name'] = name

            # âœ… Company í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ë° ìƒì„±
            with conn.cursor() as cursor:
                cursor.execute(f"""
                    CREATE TABLE IF NOT EXISTS `{tableName}` (
                        Id INT AUTO_INCREMENT PRIMARY KEY,
                        Symbol VARCHAR(128),
                        Date DATE,
                        Name VARCHAR(128),
                        UNIQUE KEY unique_symbol_date (Symbol, Date) 
                    );
                """)
                conn.commit()


            with conn.cursor() as cursor:
                cursor.execute(f"""
                    SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS
                    WHERE TABLE_NAME = '{tableName}'
                """)

                existing_columns = {row['COLUMN_NAME'] for row in cursor.fetchall()}
                
            new_columns = set(df.columns) - existing_columns        
            if new_columns:
                with conn.cursor() as cursor:
                    for col in new_columns:
                        value = df[col].iloc[0]

                        # ë‚ ì§œ íƒ€ì… í™•ì¸ (ë¬¸ìì—´ì´ì§€ë§Œ ë‚ ì§œ ë³€í™˜ ê°€ëŠ¥í•œ ê²½ìš°)
                        if isinstance(value, str):  
                            try:
                                pd.to_datetime(value)  # ë³€í™˜ ê°€ëŠ¥ ì—¬ë¶€ ì²´í¬
                                col_type = "DATE NULL"  # ë³€í™˜ ê°€ëŠ¥í•˜ë©´ DATEë¡œ ì„¤ì •
                            except ValueError:
                                col_type = "TEXT NULL" if len(value) > 128 else "VARCHAR(128) NULL"
                        
                        # Pandas datetime íƒ€ì… (ì§ì ‘ ë³€í™˜)
                        elif isinstance(value, pd.Timestamp):
                            col_type = "DATE NULL"

                        # ìˆ«ìí˜• ë°ì´í„°ëŠ” FLOAT, BIGINT ë“±ìœ¼ë¡œ ì €ì¥
                        elif isinstance(value, int):
                            col_type = "BIGINT NULL"
                        elif isinstance(value, float):
                            col_type = "FLOAT NULL"
                        
                        # ê¸°ë³¸ì ìœ¼ë¡œ VARCHAR(128)ìœ¼ë¡œ ì„¤ì •
                        else:
                            col_type = "VARCHAR(128) NULL"  

                        sql = f"ALTER TABLE {tableName} ADD COLUMN `{col}` {col_type};"

                        cursor.execute(sql)
                    
                    conn.commit()
                print(f"ğŸ› ï¸ {symbol} - ëˆ„ë½ëœ ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ: {new_columns}")

            with conn.cursor() as cursor:
                columns = ", ".join([f"`{col}`" for col in df.columns])
                placeholders = ", ".join(["%s"] * len(df.columns))
                # update_clause = ", ".join([f"`{col}` = VALUES(`{col}`)" for col in df.columns if col not in ["date", "symbol"]])
                update_clause = ", ".join([f"`{col}` = VALUES(`{col}`)" for col in df.columns])
                insert_sql = f"""
                    INSERT INTO {tableName} ({columns})
                    VALUES ({placeholders})
                    ON DUPLICATE KEY UPDATE {update_clause};
                """

                data = [tuple(row) for row in df.itertuples(index=False, name=None)]
                cursor.executemany(insert_sql, data)
                conn.commit()

            print(f"âœ… {symbol} - {tableName} ë°ì´í„° ì‚½ì… ì™„ë£Œ")

        except Exception as e:
            print(f"âš ï¸ {symbol} - {tableName} ì˜¤ë¥˜ ë°œìƒ: {e}")


    #-------------------
    # ì¬ë¬´ì¬í‘œ ë°ì´í„° ì €ì¥
    #-------------------
    def downloadFinancialStatmentAndSaveDB(symbols=[], date = ch.EDateType.YEAR):
        db = DB_FinancialStatement()
        db.connect()
        
        info = YFinanceInfo()

        if len(symbols) == 0:
            symbols = db.getSymbolList()

        for symbol in tqdm(symbols, desc="Processing Companies"):
            
            info.setCompany(symbol)

            try:
                stock_info = info.stock.info
                if not stock_info:
                    print(f"âš ï¸ {symbol} - stock.info ë¹„ì–´ìˆìŒ!")
                    continue
            except Exception as e:
                print(f"âš ï¸ {symbol} - stock.info ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
                continue

            DataDownloader.save_fs_to_db(info, db.conn, ch.EFinancialStatementType.INCOME_STATEMENT, date)
            DataDownloader.save_fs_to_db(info, db.conn, ch.EFinancialStatementType.BALANCE_SHEET, date)
            DataDownloader.save_fs_to_db(info, db.conn, ch.EFinancialStatementType.CASH_FLOW, date)

        db.disconnect()


    #-------------------
    # ê¸°ê°„ë³„ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    #-------------------
    def getStockData(tickers, start=None, end=None):
        """
        ì—¬ëŸ¬ ì¢…ëª©ì˜ ì£¼ì‹ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ
        Date, Symbol, Open, High, Low, Close, Adj Close, Volume í˜•íƒœë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜

        Parameters:
        tickers (list or str): ì£¼ì‹ ì¢…ëª©ë“¤ì˜ ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” ë‹¨ì¼ ì¢…ëª©
        start (str): ì‹œì‘ ë‚ ì§œ (ì˜ˆ: '2023-01-01')
        end (str): ë ë‚ ì§œ (ì˜ˆ: '2023-12-31')

        Returns:
        pd.DataFrame: ì •ë¦¬ëœ ì£¼ì‹ ë°ì´í„°
        """
        try:
            # auto_adjust=Falseë¡œ ì„¤ì •í•´ì„œ Dividends, Stock Splits ë“± í¬í•¨ ê°€ëŠ¥
            data = yf.download(tickers, start=start, end=end, group_by='ticker', auto_adjust=False)

            # ê²°ê³¼ë¥¼ ì €ì¥í•  ë¹ˆ ë°ì´í„°í”„ë ˆì„
            final_df = pd.DataFrame()

            if isinstance(data.columns, pd.MultiIndex):
                # ì—¬ëŸ¬ ì¢…ëª©ì¼ ë•Œ
                for ticker in tickers:
                    if ticker in data.columns.get_level_values(0):
                        temp_df = data[ticker].copy()
                        temp_df['Symbol'] = ticker
                        temp_df['Date'] = temp_df.index
                        temp_df = temp_df[['Date', 'Symbol', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']]
                        final_df = pd.concat([final_df, temp_df], axis=0)
                    else:
                        print(f"[ê²½ê³ ] '{ticker}' ë°ì´í„° ì—†ìŒ (ìƒì¥íì§€/ì˜ëª»ëœ ì‹¬ë³¼ ë“±)")
            else:
                # ë‹¨ì¼ ì¢…ëª©ì¼ ë•Œ
                data['Symbol'] = tickers if isinstance(tickers, str) else tickers[0]
                data['Date'] = data.index
                final_df = data[['Date', 'Symbol', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']].copy()

            final_df.reset_index(drop=True, inplace=True)

        except Exception as e:
            print(f"ì• ëŸ¬ ë°œìƒ! : {e}")

        return final_df


    #--------------------------------
    # getStockData ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê·¸ë˜í”„
    #--------------------------------
    @staticmethod
    def showStockDataGraph(df, value, title):
        """
        ì£¼ì‹ ë°ì´í„°í”„ë ˆì„ì„ ê¸°ë°˜ìœ¼ë¡œ íŠ¹ì • ê°’ì„ êº¾ì€ì„  ê·¸ë˜í”„ë¡œ ì‹œê°í™”í•˜ëŠ” í•¨ìˆ˜

        Parameters:
        df (pd.DataFrame): fetch_stock_dataë¡œ ìƒì„±ëœ ë°ì´í„°í”„ë ˆì„
        value (str): ê·¸ë˜í”„ì— ì‚¬ìš©í•  ì»¬ëŸ¼ëª… (ì˜ˆ: 'Close', 'Open', 'High', 'Low', 'Volume')
        title (str): ê·¸ë˜í”„ì˜ ì œëª©

        Returns:
        None (ê·¸ë˜í”„ ì¶œë ¥)
        """

        prev_renderer = pio.renderers.default
        # Plotly ê¸°ë³¸ ë Œë”ëŸ¬ ì„¤ì • (ì˜µì…˜: 'browser', 'notebook', 'png' ë“±. í•„ìš”ì— ë”°ë¼ ë³€ê²½ ê°€ëŠ¥)
        pio.renderers.default = 'browser'
        
        # ê·¸ë˜í”„ ê·¸ë¦´ ê°ì²´ ìƒì„±
        fig = go.Figure()

        # ê³ ìœ í•œ ì¢…ëª©ë“¤ì— ëŒ€í•´ ê°ê° ê·¸ë˜í”„ ì¶”ê°€
        for symbol in df['Symbol'].unique():
            symbol_df = df[df['Symbol'] == symbol]
            fig.add_trace(
                go.Scatter(
                    x=symbol_df['Date'],
                    y=symbol_df[value],
                    mode='lines',
                    name=symbol  # ì¢…ëª©ëª…ì„ ë¼ë²¨ë¡œ ì‚¬ìš©
                )
            )

        # ë ˆì´ì•„ì›ƒ ì„¤ì •
        fig.update_layout(
            title=title,
            xaxis_title='Date',
            yaxis_title=value,
            legend_title='Symbol',
            hovermode='x unified'
        )

        # ê·¸ë˜í”„ ì¶œë ¥
        fig.show()

        # ì›ë˜ëŒ€ë¡œ ë³µê·€
        pio.renderers.default = prev_renderer


    #--------------------
    # ì£¼ê°€ DBì €ì¥
    #--------------------
    @staticmethod
    def insert_stock_data(conn, df):
        """
        fetch_stock_dataë¡œ ê°€ì ¸ì˜¨ DataFrameì„ MySQL StockPrices í…Œì´ë¸”ì— ì €ì¥
        :param df: fetch_stock_dataë¡œ ê°€ì ¸ì˜¨ ë°ì´í„°í”„ë ˆì„
        :param db_config: MySQL ì ‘ì† ì •ë³´ (host, user, password, db, port)
        """

        # DB ì—°ê²°
        connection = conn

        # âœ… Date ì»¬ëŸ¼ ì‹œê°„ ì œê±° (datetime -> date)
        df['Date'] = pd.to_datetime(df['Date']).dt.date
        
        # âœ… NaN -> None ë³€í™˜ (ìˆ«ìí˜• ì»¬ëŸ¼ í¬í•¨ safe ì²˜ë¦¬)
        df = df.astype(object).where(pd.notnull(df), None)

        # DataFrameì„ íŠœí”Œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (adj_closeëŠ” Closeë¡œ ì±„ì›Œë„£ìŒ)
        data_to_insert = list(
            df[['Date', 'Symbol', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']].itertuples(index=False, name=None)
        )

        sql = """
            INSERT INTO StockPrices (date, symbol, open, high, low, close, volume, adj_close)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
            ON DUPLICATE KEY UPDATE
                open = VALUES(open),
                high = VALUES(high),
                low = VALUES(low),
                close = VALUES(close),
                volume = VALUES(volume),
                adj_close = VALUES(adj_close);
        """

        try:
            with connection.cursor() as cursor:
                cursor.executemany(sql, data_to_insert)
                print(f"{cursor.rowcount} rows inserted/updated successfully.")
            connection.commit()
        except Exception as e:
            print("Error occurred:", e)
            connection.rollback()


    #--------------------
    # ì‹œê³„ì—´ ê°€ì ¸ì™€ DBì— ì €ì¥
    #--------------------
    @staticmethod
    def downloadStockDataAndSaveDB(start=None, end=None, symbols=[], batch_size=100, sleep_sec=5, startIndex=0, endIndex=None):
        """
        ì£¼ì‹ ë°ì´í„°ë¥¼ ì¼ì • ê°œìˆ˜ì”© ë‚˜ëˆ ì„œ ë‹¤ìš´ë¡œë“œí•˜ê³  ì €ì¥í•˜ëŠ” í•¨ìˆ˜

        Parameters:
        start (str): ì‹œì‘ ë‚ ì§œ (ì˜ˆ: '2023-01-01')
        end (str): ë ë‚ ì§œ (ì˜ˆ: '2023-12-31')
        symbols (list): ì£¼ì‹ ì‹¬ë³¼ ë¦¬ìŠ¤íŠ¸
        batch_size (int): í•œ ë²ˆì— ì²˜ë¦¬í•  ì‹¬ë³¼ì˜ ìˆ˜ (ê¸°ë³¸ê°’: 100)
        sleep_sec (int): ê° batch ê°„ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
        startIndex (int): ì‹¬ë³¼ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì‹œì‘í•  ì¸ë±ìŠ¤ (ê¸°ë³¸ 0)
        endIndex (int): ì‹¬ë³¼ ë¦¬ìŠ¤íŠ¸ì—ì„œ ëë‚¼ ì¸ë±ìŠ¤ (ê¸°ë³¸ None, ëê¹Œì§€)
        """

        if len(symbols) == 0:
            fs_db = DB_FinancialStatement()
            fs_db.connect()
            symbols = fs_db.getSymbolList()
            fs_db.disconnect()

        # ì‹¬ë³¼ êµ¬ê°„ ì˜ë¼ë‚´ê¸°
        if endIndex is None or endIndex > len(symbols):
            endIndex = len(symbols)  # ë²”ìœ„ ì´ˆê³¼ ë°©ì§€

        symbols = symbols[startIndex:endIndex]  # ì›í•˜ëŠ” êµ¬ê°„ë§Œ ì‚¬ìš©

        total = len(symbols)
        total_batches = math.ceil(total / batch_size)

        print(f"ì´ {total}ê°œì˜ ì‹¬ë³¼ì„ {batch_size}ê°œì”© ë‚˜ëˆ ì„œ {total_batches}ë²ˆì— ê±¸ì³ ì²˜ë¦¬í•©ë‹ˆë‹¤. (ì‹¬ë³¼ ì¸ë±ìŠ¤ ë²”ìœ„: {startIndex} ~ {endIndex})")

        for i in range(0, total, batch_size):
            batch = symbols[i:i + batch_size]
            print(f"[{i // batch_size + 1}/{total_batches}] {len(batch)}ê°œ ì‹¬ë³¼ ë‹¤ìš´ë¡œë“œ ì¤‘...")

            db = DB_Stock()
            db.connect()

            try:
                df = DataDownloader.getStockData(batch, start, end)
                df = df.where(pd.notnull(df), None)
                if not df.empty:
                    DataDownloader.insert_stock_data(db.conn, df)
                    print(f"[{i // batch_size + 1}/{total_batches}] ë°ì´í„° ì €ì¥ ì™„ë£Œ.")
                else:
                    print(f"[{i // batch_size + 1}/{total_batches}] ë°ì´í„° ì—†ìŒ.")
            except Exception as e:
                print(f"[{i // batch_size + 1}/{total_batches}] ì—ëŸ¬ ë°œìƒ: {e}")
            finally:
                db.disconnect()

            # ë‹¤ìŒ batchë¥¼ ìœ„í•´ ëŒ€ê¸° (ì ì§„ì  ë”œë ˆì´)
            if i + batch_size < total:
                print(f"{sleep_sec}ì´ˆ ëŒ€ê¸° ì¤‘...")
                time.sleep(sleep_sec)

        print("ëª¨ë“  ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ.")


    #--------------------
    # ë¯¸êµ­ì£¼ì‹ ì‹¬ë³¼ë¡œë“œ
    #--------------------
    @staticmethod
    def load_nysc_symbol():

        # 2. User-Agent ë³€ê²½ ë° ìë™í™” í‘œì‹œ ì œê±°
        # ì…€ë ˆë‹ˆì›€ì€ ë¸Œë¼ìš°ì €ê°€ ìë™í™”ëœ ê²ƒì„ì„ í˜ì´ì§€ì— í‘œì‹œ. User-Agentë¥¼ ì¼ë°˜ ë¸Œë¼ìš°ì €ì²˜ëŸ¼ ì„¤ì •í•˜ê³ , webdriver í”Œë˜ê·¸ë¥¼ ì œê±°í•˜ë©´ íƒì§€ë¥¼ í”¼í•  ê°€ëŠ¥ì„±ì´ ìˆì–´.
        options = Options()
        options.add_argument("--disable-blink-features=AutomationControlled")
        options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/91.0.4472.124 Safari/537.36")
        options.add_argument("--start-maximized")

        driver = webdriver.Chrome(options=options)
        driver.execute_cdp_cmd("Page.addScriptToEvaluateOnNewDocument", {
            "source": """
            Object.defineProperty(navigator, 'webdriver', {get: () => undefined})
            """
        })

        driver.get("https://www.nyse.com/listings_directory/stock")

        # ì¿ í‚¤ ë™ì˜ íŒì—… ì²˜ë¦¬
        try:
            accept_button = WebDriverWait(driver, 10).until(
                EC.element_to_be_clickable((By.XPATH, '//button[contains(text(), "Accept All Cookies")]'))
            )
            accept_button.click()
            print("ì¿ í‚¤ ë™ì˜ ì™„ë£Œ")
        except Exception as e:
            print(f"ì¿ í‚¤ ë™ì˜ ë²„íŠ¼ ì°¾ê¸° ì‹¤íŒ¨: {e}")

        # ì…€ë ˆë‹ˆì›€ì—ì„œ í˜ì´ì§€ ìº¡ì³í•œ ê²ƒ
        data = []

        while True:
            # í…Œì´ë¸” ë°ì´í„°ê°€ ë‚˜íƒ€ë‚  ë•Œê¹Œì§€ ìµœëŒ€ 20ì´ˆ ê¸°ë‹¤ë¦¼
            WebDriverWait(driver, 20).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, ".table-data.w-full.table-border-rows tbody tr"))
            )

            while(True):           
                try:
                    html = driver.page_source 
                    soup = BeautifulSoup(html, 'html.parser')
                    tag = soup.select_one(".table-data.w-full.table-border-rows")            
                    infos = tag.select("tbody tr")

                    for info in infos:
                        symbol = info.select_one("td a").text.strip()
                        url = info.select_one("td a")["href"]
                        name = info.select("td")[1].text.strip()
                        data.append([symbol,name,url])
                    print(f"{soup.select_one('.px-2.text-gray-500').text} ë‹¤ìš´ì™„ë£Œ! len : {len(data)}")

                    break

                except Exception as e:
                    print(f"ì¬ì‹œë„ : {e}")
                    time.sleep(3)
                    continue
                  
            try:
                btn = WebDriverWait(driver, 10).until(
                    EC.element_to_be_clickable((By.CSS_SELECTOR, 
                    r"#integration-id-fcc63aa > div.flex-1 > div.px-3.lg\:px-24 > div.flex.flex-col.flex-wrap.gap-x-8.md\:flex-row > div.basis-2\/3 > div.\!text-center > div > ul > li:nth-child(8) > a"))
                )
                btn.click()

                # ìƒˆë¡œìš´ í˜ì´ì§€ê°€ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸°
                WebDriverWait(driver, 10).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, ".table-data.w-full.table-border-rows tbody tr"))
                )

            except NoSuchElementException:
                print("ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í˜ì´ì§€ íƒìƒ‰ ì¢…ë£Œ.")
                break

            except TimeoutException:
                print("âŒ [TimeoutException] ë²„íŠ¼ í´ë¦­ ë˜ëŠ” í˜ì´ì§€ ë¡œë“œê°€ ì‹œê°„ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. í˜ì´ì§€ íƒìƒ‰ ì¢…ë£Œ.")
                break

        df = pd.DataFrame(data, columns=['symbol', 'name', 'url'])
        df.dropna(subset=['open', 'high', 'low', 'close', 'volume'], how='all')
        return df
    

    @staticmethod
    def fetch_all_nyse_data(output_csv="nyse_listings_partial.csv"):
        url = "https://www.nyse.com/api/quotes/filter"
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/91.0.4472.124 Safari/537.36",
            "Content-Type": "application/json",
        }

        payload = {
            "instrumentType": "EQUITY",           # í˜¹ì€ "ETF"ë¡œ ë°”ê¾¸ë©´ ETFë§Œ ì¡°íšŒ
            "pageNumber": 1,
            "sortColumn": "NORMALIZED_TICKER",
            "sortOrder": "ASC",
            "maxResultsPerPage": 100,             # í•œ í˜ì´ì§€ë‹¹ ìµœëŒ€ ìš”ì²­ ìˆ˜ (ë³´í†µ 100ê¹Œì§€ ê°€ëŠ¥)
            "filterToken": ""
        }

        all_data = []
        page = 1

        while True:
            print(f"Fetching page {page}...")
            payload["pageNumber"] = page
            response = requests.post(url, headers=headers, json=payload)
            
            if response.status_code != 200:
                print(f"âŒ Error on page {page}: HTTP {response.status_code}")
                break

            data = response.json()
            if not data:
                print("âœ… No more data found. Stopping.")
                break

            all_data.extend(data)
            print(f"âœ… Page {page} done, total records: {len(all_data)}")

            # ğŸŒŸ ë°ì´í„° ì¤‘ê°„ ì €ì¥
            df_partial = pd.DataFrame(all_data)
            df_partial.to_csv(output_csv, index=False)
            print(f"ğŸ“¥ ì¤‘ê°„ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {output_csv}")

            page += 1
            time.sleep(2)  # ì„œë²„ ë¶€í•˜ ë°©ì§€ ë° ë´‡ íƒì§€ ë°©ì§€ìš© ë”œë ˆì´

        df_final = pd.DataFrame(all_data)
        return df_final


    @staticmethod
    def downloadNYSE_SymbolAndSaveDB():
        df = DataDownloader.load_nysc_symbol()

        if df.empty:
            print(f"df is null!")
            return
        
        db = MySQLConnector()
        db.connect(ch.DBName.DB_NYSE)

        try:
            with db.conn.cursor() as cursor:
                values = [tuple(x) for x in df[['symbol', 'name', 'url']].to_numpy()]

                # âœ… ì¿¼ë¦¬ ì¤€ë¹„ (ON DUPLICATE KEY UPDATEë¡œ upsert)
                sql = """
                INSERT INTO Symbol_Stock (symbol, name, url)
                VALUES (%s, %s, %s)
                ON DUPLICATE KEY UPDATE
                    name = VALUES(name),
                    url = VALUES(url),
                    update_at = CURRENT_TIMESTAMP;
                """
                # âœ… executemanyë¡œ ì¼ê´„ ì²˜ë¦¬
                cursor.executemany(sql, values)
            db.conn.commit()

        except Exception as e:
            print(f"quary error : {e}")

        print(f"NYSE ì‹¬ë³¼ ë‹¤ìš´ë¡œë“œ : {len(df)}")

        db.disconnect()
        
        
        

    #--------------------
    # ê¸°ì—…ì •ë³´ ë¡œë“œí•˜ê¸°
    #--------------------
    @staticmethod
    def save_company_info_to_db(stockInfo, conn):
        try:
            info = stockInfo.stock.info
            symbol = stockInfo.ticker.upper()

            with conn.cursor() as cursor:
                cursor.execute("""
                    SELECT COUNT(*) AS count 
                    FROM information_schema.tables 
                    WHERE table_schema = DATABASE() AND table_name = 'Company';
                """)
                result = cursor.fetchone()
                if result['count'] == 0:
                    cursor.execute("""
                        CREATE TABLE Company (
                            id INT AUTO_INCREMENT PRIMARY KEY,
                            symbol VARCHAR(255) UNIQUE
                        );
                    """)
                    conn.commit()
                    print(f"ğŸ†• Company í…Œì´ë¸” ìƒì„± ì™„ë£Œ")

            with conn.cursor() as cursor:
                cursor.execute("SELECT COLUMN_NAME, DATA_TYPE FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = 'Company'")
                existing_columns = {row['COLUMN_NAME']: row['DATA_TYPE'] for row in cursor.fetchall()}

            # ê¸°ì¡´ info ë°ì´í„°ë¥¼ ë³µì‚¬
            data = {key: info.get(key, None) for key in info.keys()}
            data["symbol"] = symbol
         
            # ìƒì¥ì¼ í‘œì‹œ
            first_trade_date = data["firstTradeDateMilliseconds"]
            data['firstTradeDate'] = datetime.datetime.fromtimestamp(first_trade_date/1000).date()

            data = DataDownloader.get_mark_spac_dict(data)

            # ë°ì´í„°ì— count ì¶”ê°€, companyOfficers ì œê±°
            data.pop("companyOfficers", None)

            # âœ… ëˆ„ë½ëœ ì»¬ëŸ¼ ìë™ ì¶”ê°€
            missing_columns = set(data.keys()) - set(existing_columns.keys())

            if missing_columns:
                with conn.cursor() as cursor:
                    for col in missing_columns:
                        value = data[col]
                        if col == "firstTradeDate":
                            col_type = "DATE NULL"  # ê°œìˆ˜ëŠ” ì •ìˆ˜í˜•
                        elif isinstance(value, int):
                            col_type = "BIGINT NULL"
                        elif isinstance(value, float):
                            col_type = "FLOAT NULL"
                        elif isinstance(value, str) and len(value) > 255:
                            col_type = "TEXT NULL"
                        else:
                            col_type = "VARCHAR(255) NULL"
                        sql = f"ALTER TABLE Company ADD COLUMN `{col}` {col_type};"
                        cursor.execute(sql)
                    conn.commit()
                print(f"ğŸ› ï¸ {symbol} - ëˆ„ë½ëœ ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ: {missing_columns}")

            # âœ… dict, listëŠ” JSON ë¬¸ìì—´ë¡œ ë³€í™˜ (ì´ë¯¸ companyOfficersëŠ” ì œê±°ë¨)
            for key, value in data.items():
                if isinstance(value, (dict, list)):
                    data[key] = json.dumps(value)

            # âœ… ë°ì´í„° ì‚½ì… ë˜ëŠ” ì—…ë°ì´íŠ¸
            columns = ", ".join(data.keys())
            placeholders = ", ".join(["%s"] * len(data))
            update_clause = ", ".join([f"{key} = VALUES({key})" for key in data.keys() if key != "symbol"])

            with conn.cursor() as cursor:
                sql = f"""
                INSERT INTO Company ({columns})
                VALUES ({placeholders})
                ON DUPLICATE KEY UPDATE {update_clause};
                """
                cursor.execute(sql, tuple(data.values()))
                conn.commit()
            sys.stdout.write(f"âœ… {symbol} - ë°ì´í„° ì €ì¥ ì™„ë£Œ")
            sys.stdout.flush()

        except Exception as e:
            print(f"âš ï¸ {symbol} - ì˜¤ë¥˜ ë°œìƒ: {e}")


    # ì‹¬ë³¼ê³¼ í•¨ê»˜ ì‹¤íŒ¨ë„ ë°˜í™˜
    @staticmethod
    def process_symbol(symbol):
        try:
            time.sleep(random.uniform(0.5, 1.5))  # ìš”ì²­ ì „ì— ëœë¤ ëŒ€ê¸°
            info = YFinanceInfo()
            info.setCompany(symbol)
            return symbol, info
        except Exception as e:
            print(f"âš ï¸ Error in process_symbol for {symbol}: {e}")
            return symbol, None


    @staticmethod
    def downloadCompanyInfoAndSaveDB(symbols=[]):

        with DB_FinancialStatement() as fs:

            if len(symbols) == 0:
                with DB_NYSE() as nyse:
                    symbols = nyse.getSymbolList()
                
            max_workers = min(5, len(symbols))  # ì ì ˆí•œ ì›Œì»¤ ìˆ˜ ê²°ì • (ë„ˆë¬´ ë§ì€ ìŠ¤ë ˆë“œ ë°©ì§€)

            # ë³‘ë ¬ ì²˜ë¦¬
            with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
                futures = {executor.submit(DataDownloader.process_symbol, symbol): symbol for symbol in symbols}

                for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures), desc="Processing Companies"):
                    symbol = futures[future]  # í•­ìƒ ê°€ì ¸ì˜¤ê¸°
                    try:
                        result_symbol, info = future.result()
                        if info and info.stock is not None:
                            DataDownloader.save_company_info_to_db(info, fs.conn)
                        else:
                            print(f"ğŸš¨ {result_symbol}: No stock data available.")
                    except Exception as e:
                        print(f"âŒ Error processing {symbol}: {e}")

    

    @staticmethod
    def downloadCompanyInfoAndSaveDB_V2(symbols:list):
        with DB_FinancialStatement() as fs:
            for symbol in symbols:
                try:
                    info = DataDownloader.process_symbol(symbol)
                    if info and info.stock is not None:
                        DataDownloader.save_company_info_to_db(info, fs.conn)
                    else:
                        print(f"ğŸš¨ {symbol}: No stock data available.")
                except Exception as e:
                    print(f"âŒ Error processing {symbol}: {e}")



    @staticmethod
    def upload_to_nyse():
        csv_file = 'nyse_listings_final.csv'
        
        df = pd.read_csv(csv_file)
        df = df[['symbolTicker','instrumentName','micCode','url']].copy()
        df = df.where(pd.notna(df), None)

        table_name = 'Stock'

        with DB_NYSE() as nyse:
            with nyse.conn.cursor() as cursor:
                create_table_query = f"""
                    CREATE TABLE IF NOT EXISTS {table_name} (
                        id INT AUTO_INCREMENT PRIMARY KEY,
                        symbolTicker VARCHAR(50) NOT NULL UNIQUE,
                        instrumentName VARCHAR(255),
                        micCode VARCHAR(50),
                        url TEXT,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
                    );
                    """
                cursor.execute(create_table_query)

                insert_query = f"""
                    INSERT IGNORE INTO {table_name} (symbolTicker, instrumentName, micCode, url)
                    VALUES (%s, %s, %s, %s)
                    """
                
                for index, row in df.iterrows():
                    data = (row['symbolTicker'], row['instrumentName'], row['micCode'], row['url'])
                    cursor.execute(insert_query, data)

            
            nyse.conn.commit()
            print(f"{cursor.rowcount} rows inserted.")


    
    @staticmethod
    def get_mark_spac_dict(record: dict) -> dict:
        try:
            # í•„ìˆ˜ í‚¤ í™•ì¸
            required_keys = ['symbol', 'longBusinessSummary', 'industry', 'sector']
            for key in required_keys:
                if key not in record:
                    print(f"â—í•„ìˆ˜ í‚¤ ëˆ„ë½: {key}")
                    record['isSpec'] = None
                    return record

            # ê°’ë“¤ì„ ì†Œë¬¸ìë¡œ ë³€í™˜ (str íƒ€ì… ê°•ì œ)
            description = str(record.get('longBusinessSummary', '')).lower()
            industry = str(record.get('industry', '')).lower()
            sector = str(record.get('sector', '')).lower()
            symbol = str(record.get('symbol', '')).upper()

             # ğŸ’¡ companyOfficers ì²˜ë¦¬
            officers = record.get("companyOfficers", [])
            if isinstance(officers, list):
                officers = len(officers)
            else:
                officers = 0

            # 1ï¸âƒ£ í‚¤ì›Œë“œ ê¸°ë°˜
            keywords = ["spac", "blank check", "special purpose acquisition"]
            keyword_hit = any(kw in description or kw in industry or kw in sector for kw in keywords)

            # 2ï¸âƒ£ industry ê¸°ë°˜
            industry_based = industry in ["shell companies", "capital markets", "asset management"]

            if officers != -1:
                # 3ï¸âƒ£ ì„ì› ìˆ˜ ê¸°ë°˜
                officer_based = officers <= 0
            else:
                officer_based = False

            # 4ï¸âƒ£ í‹°ì»¤ ë„¤ì´ë° ê¸°ë°˜
            ticker_based = any(x in symbol for x in ["-U", "-WS", "-R"])

            # ìµœì¢… íŒë³„ (ì—¬ê¸°ì„œëŠ” officer ê¸°ë°˜ê¹Œì§€ ê³ ë ¤í• ì§€ ì„ íƒ ê°€ëŠ¥)
            is_spac = keyword_hit or industry_based or officer_based or ticker_based

            # ê²°ê³¼ ì¶”ê°€
            record['isSpec'] = is_spac

        except Exception as e:
            print(f"[{record.get('symbol', 'UNKNOWN')}] íŒë³„ ì‹¤íŒ¨: {e}")
            record['isSpec'] = None

        return record
    
